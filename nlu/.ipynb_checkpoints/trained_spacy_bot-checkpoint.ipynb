{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a964a3b5-777e-4329-888b-7f94f0256db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Losses: {'ner': np.float32(784.6445)}\n",
      "Iteration 2\n",
      "Losses: {'ner': np.float32(456.4576)}\n",
      "Iteration 3\n",
      "Losses: {'ner': np.float32(16.20474)}\n",
      "Iteration 4\n",
      "Losses: {'ner': np.float32(0.07802634)}\n",
      "Iteration 5\n",
      "Losses: {'ner': np.float32(4.641822e-12)}\n",
      "Iteration 6\n",
      "Losses: {'ner': np.float32(2.1370937e-18)}\n",
      "Iteration 7\n",
      "Losses: {'ner': np.float32(7.404255e-21)}\n",
      "Iteration 8\n",
      "Losses: {'ner': np.float32(2.5152164e-35)}\n",
      "Iteration 9\n",
      "Losses: {'ner': np.float32(2.3666992e-35)}\n",
      "Iteration 10\n",
      "Losses: {'ner': np.float32(2.9567711e-38)}\n",
      "Iteration 11\n",
      "Losses: {'ner': np.float32(2.9329711e-34)}\n",
      "Iteration 12\n",
      "Losses: {'ner': np.float32(1.059711e-38)}\n",
      "Iteration 13\n",
      "Losses: {'ner': np.float32(1.417541e-32)}\n",
      "Iteration 14\n",
      "Losses: {'ner': np.float32(3.1501428e-29)}\n",
      "Iteration 15\n",
      "Losses: {'ner': np.float32(1.2822e-41)}\n",
      "Iteration 16\n",
      "Losses: {'ner': np.float32(2.5972427e-35)}\n",
      "Iteration 17\n",
      "Losses: {'ner': np.float32(2.06271e-40)}\n",
      "Iteration 18\n",
      "Losses: {'ner': np.float32(1.59258e-40)}\n",
      "Iteration 19\n",
      "Losses: {'ner': np.float32(3.643e-42)}\n",
      "Iteration 20\n",
      "Losses: {'ner': np.float32(8.35107e-34)}\n",
      "Iteration 21\n",
      "Losses: {'ner': np.float32(5.397657e-32)}\n",
      "Iteration 22\n",
      "Losses: {'ner': np.float32(1.5327683e-37)}\n",
      "Iteration 23\n",
      "Losses: {'ner': np.float32(1.2772315e-28)}\n",
      "Iteration 24\n",
      "Losses: {'ner': np.float32(3.9835552e-38)}\n",
      "Iteration 25\n",
      "Losses: {'ner': np.float32(5.69398e-36)}\n",
      "Iteration 26\n",
      "Losses: {'ner': np.float32(1.1561e-41)}\n",
      "Iteration 27\n",
      "Losses: {'ner': np.float32(3.8973725e-37)}\n",
      "Iteration 28\n",
      "Losses: {'ner': np.float32(1.46229e-39)}\n",
      "Iteration 29\n",
      "Losses: {'ner': np.float32(2.508656e-35)}\n",
      "Iteration 30\n",
      "Losses: {'ner': np.float32(4.502442e-39)}\n",
      "\n",
      "✅ Model saved to trained_realestate_ner_2\n",
      "\n",
      "--- Test the trained model ---\n",
      "\n",
      "Parsed Input for Model:\n",
      "{'LOCATION': None, 'PRICE': None, 'PROPERTY_TYPE': None, 'BEDROOMS': None, 'BATHROOMS': None, 'AMENITY': None}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Define labels\n",
    "LABELS = [\"LOCATION\", \"PRICE\", \"PROPERTY_TYPE\", \"BEDROOMS\", \"BATHROOMS\", \"AMENITY\"]\n",
    "\n",
    "# Function to load and auto-align entities from CSV\n",
    "def generate_spacy_ner_data(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    formatted_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        entities = []\n",
    "\n",
    "        for label in LABELS:\n",
    "            value = str(row.get(label, \"\")).strip()\n",
    "            if value and value.lower() != \"nan\":\n",
    "                start = text.lower().find(value.lower())\n",
    "                if start != -1:\n",
    "                    end = start + len(value)\n",
    "                    entities.append((start, end, label))\n",
    "                else:\n",
    "                    print(f\"⚠️ Could not find '{value}' in: '{text}'\")\n",
    "\n",
    "        formatted_data.append((text, {\"entities\": entities}))\n",
    "\n",
    "    return formatted_data\n",
    "\n",
    "# Load and process training data\n",
    "TRAIN_DATA = generate_spacy_ner_data(\"real_estate_ner_dataset.csv\")\n",
    "\n",
    "# Validate entity alignment (optional but good practice)\n",
    "def validate_entities(nlp, training_data):\n",
    "    from spacy.training import offsets_to_biluo_tags\n",
    "    for text, annotations in training_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        try:\n",
    "            tags = offsets_to_biluo_tags(doc, annotations[\"entities\"])\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Misaligned entity in: '{text}'\\nReason: {e}\")\n",
    "\n",
    "# Load blank model\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# Add labels to NER\n",
    "for label in LABELS:\n",
    "    ner.add_label(label)\n",
    "\n",
    "# Train the model\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for iteration in range(30):\n",
    "        print(f\"Iteration {iteration + 1}\")\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.5))\n",
    "        for batch in batches:\n",
    "            examples = []\n",
    "            for text, annotations in batch:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                examples.append(example)\n",
    "            nlp.update(examples, drop=0.35, losses=losses)\n",
    "        print(\"Losses:\", losses)\n",
    "\n",
    "# Save model\n",
    "output_dir = Path(\"trained_realestate_ner_2\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"\\n✅ Model saved to {output_dir}\")\n",
    "\n",
    "# Load and test model\n",
    "print(\"\\n--- Test the trained model ---\")\n",
    "test_text = \"I want a villa in Cap Cana with 5 bedrooms and a pool for $450,000\"\n",
    "loaded_nlp = spacy.load(output_dir)\n",
    "doc = loaded_nlp(test_text)\n",
    "\n",
    "# Show extracted entities\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "# Parse entities into model input format\n",
    "def ner_output_to_model_input(doc, all_labels):\n",
    "    input_dict = {label: None for label in all_labels}\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in input_dict:\n",
    "            input_dict[ent.label_] = ent.text\n",
    "    return input_dict\n",
    "\n",
    "parsed_input = ner_output_to_model_input(doc, LABELS)\n",
    "print(\"\\nParsed Input for Model:\")\n",
    "print(parsed_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593aacf0-079a-43e1-b55f-47f8cde64e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_clean)",
   "language": "python",
   "name": "tf_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
