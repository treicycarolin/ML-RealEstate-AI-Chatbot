{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353dbc3d-b6bf-4c3c-9c35-e5054f5c6c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Losses {'ner': np.float32(841.6163)}\n",
      "Iteration 2\n",
      "Losses {'ner': np.float32(691.1465)}\n",
      "Iteration 3\n",
      "Losses {'ner': np.float32(409.45844)}\n",
      "Iteration 4\n",
      "Losses {'ner': np.float32(391.354)}\n",
      "Iteration 5\n",
      "Losses {'ner': np.float32(368.9229)}\n",
      "Iteration 6\n",
      "Losses {'ner': np.float32(398.9683)}\n",
      "Iteration 7\n",
      "Losses {'ner': np.float32(417.88498)}\n",
      "Iteration 8\n",
      "Losses {'ner': np.float32(403.72476)}\n",
      "Iteration 9\n",
      "Losses {'ner': np.float32(255.02385)}\n",
      "Iteration 10\n",
      "Losses {'ner': np.float32(177.43863)}\n",
      "Iteration 11\n",
      "Losses {'ner': np.float32(139.8552)}\n",
      "Iteration 12\n",
      "Losses {'ner': np.float32(131.13374)}\n",
      "Iteration 13\n",
      "Losses {'ner': np.float32(115.703094)}\n",
      "Iteration 14\n",
      "Losses {'ner': np.float32(88.49871)}\n",
      "Iteration 15\n",
      "Losses {'ner': np.float32(74.85264)}\n",
      "Iteration 16\n",
      "Losses {'ner': np.float32(101.781075)}\n",
      "Iteration 17\n",
      "Losses {'ner': np.float32(97.36516)}\n",
      "Iteration 18\n",
      "Losses {'ner': np.float32(47.36981)}\n",
      "Iteration 19\n",
      "Losses {'ner': np.float32(41.482944)}\n",
      "Iteration 20\n",
      "Losses {'ner': np.float32(34.46643)}\n",
      "Iteration 21\n",
      "Losses {'ner': np.float32(13.086074)}\n",
      "Iteration 22\n",
      "Losses {'ner': np.float32(14.452482)}\n",
      "Iteration 23\n",
      "Losses {'ner': np.float32(7.3657355)}\n",
      "Iteration 24\n",
      "Losses {'ner': np.float32(2.5264914)}\n",
      "Iteration 25\n",
      "Losses {'ner': np.float32(4.024534)}\n",
      "Iteration 26\n",
      "Losses {'ner': np.float32(1.6901482)}\n",
      "Iteration 27\n",
      "Losses {'ner': np.float32(0.6388432)}\n",
      "Iteration 28\n",
      "Losses {'ner': np.float32(0.09542216)}\n",
      "Iteration 29\n",
      "Losses {'ner': np.float32(0.043347366)}\n",
      "Iteration 30\n",
      "Losses {'ner': np.float32(0.19747607)}\n",
      "Model saved to beta_test_model\n",
      "\n",
      "--- Test the trained model ---\n",
      "building -> PROPERTY_TYPE\n",
      "La Romana -> LOCATION\n",
      "10 bathrooms -> BATHROOMS\n",
      "$3,500,000 -> PRICE\n",
      "\n",
      "Parsed Input for Model:\n",
      "{'LOCATION': 'La Romana', 'PRICE': '$3,500,000', 'PROPERTY_TYPE': 'building', 'BEDROOMS': None, 'BATHROOMS': '10 bathrooms', 'AMENITY': None}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Load your training data\n",
    "from generated_train_data import TRAIN_DATA\n",
    "\n",
    "# Define the labels manually based on your dataset\n",
    "LABELS = [\"LOCATION\", \"PRICE\", \"PROPERTY_TYPE\", \"BEDROOMS\", \"BATHROOMS\", \"AMENITY\"]\n",
    "\n",
    "# Load or create a blank English model\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# Add labels to the NER component\n",
    "for label in LABELS:\n",
    "    ner.add_label(label)\n",
    "\n",
    "# Disable other pipeline components during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for iteration in range(30):\n",
    "        print(f\"Iteration {iteration + 1}\")\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "\n",
    "        # Create Example objects\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.5))\n",
    "        for batch in batches:\n",
    "            examples = []\n",
    "            for text, annotations in batch:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                examples.append(example)\n",
    "            nlp.update(examples, drop=0.35, losses=losses)\n",
    "\n",
    "        print(\"Losses\", losses)\n",
    "\n",
    "# Save the trained model\n",
    "output_dir = Path(\"beta_test_model\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")\n",
    "\n",
    "# Load the trained model and test it\n",
    "print(\"\\n--- Test the trained model ---\")\n",
    "test_text = \"Searching for a building in La Romana with 10 bathrooms for $3,500,000\"\n",
    "loaded_nlp = spacy.load(output_dir)\n",
    "doc = loaded_nlp(test_text)\n",
    "\n",
    "# Print NER output\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "# Convert NER results to model input\n",
    "def ner_output_to_model_input(doc, all_labels):\n",
    "    input_dict = {label: None for label in all_labels}\n",
    "    for ent in doc.ents:\n",
    "        label = ent.label_\n",
    "        if label in input_dict:\n",
    "            input_dict[label] = ent.text\n",
    "    return input_dict\n",
    "\n",
    "parsed_input = ner_output_to_model_input(doc, LABELS)\n",
    "print(\"\\nParsed Input for Model:\")\n",
    "print(parsed_input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_clean)",
   "language": "python",
   "name": "tf_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
